{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from collections import namedtuple, deque\n",
    "from ale_py import ALEInterface\n",
    "import wandb\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import logging\n",
    "from utils_AC import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = all messages, 1 = filter out INFO, 2 = filter out WARNING, 3 = filter out ERROR\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "gym_logger = logging.getLogger('gym')\n",
    "gym_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API KEY: 73c9a156b91f3e0c01c3d5f332d23bfc66f4cdbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mroysgc\u001b[0m (\u001b[33mrl_proj\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcc3ee1eb994da5821e1c53b4c87139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011134662700000004, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/roy/Desktop/EXAMPML/RL_Project/Assault/AC/wandb/run-20231212_230331-7zgejh4l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rl_proj/ActorCritic/runs/7zgejh4l' target=\"_blank\">fallen-cherry-3</a></strong> to <a href='https://wandb.ai/rl_proj/ActorCritic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rl_proj/ActorCritic' target=\"_blank\">https://wandb.ai/rl_proj/ActorCritic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rl_proj/ActorCritic/runs/7zgejh4l' target=\"_blank\">https://wandb.ai/rl_proj/ActorCritic/runs/7zgejh4l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rl_proj/ActorCritic/runs/7zgejh4l?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fdf27f44af0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"ActorCritic\", entity = \"rl_proj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 7\n",
      "Model: \"actor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  6176      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           multiple                  32832     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  multiple                 256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           multiple                  36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  11534848  \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,614,631\n",
      "Trainable params: 11,614,503\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"critic\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           multiple                  6176      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           multiple                  32832     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           multiple                  36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  11534848  \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,611,297\n",
      "Trainable params: 11,611,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "step:  14 action:  0  reward:  21.0\n",
      "Lives:  4\n",
      "step:  56 action:  6  reward:  21.0\n",
      "Lives:  4\n",
      "step:  74 action:  1  reward:  21.0\n",
      "Lives:  4\n",
      "Episode: 1, Reward: 63.0, Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with reward: 63.0\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "Action probabilities: [[0.1422158  0.1355353  0.14893652 0.14380349 0.14022204 0.1400763\n",
      "  0.14921048]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fcdebd722b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-fcdebd722b3c>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mcritic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_target\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mcritic_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0mcritic_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_global_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;31m# in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   return [\n\u001b[0;32m--> 582\u001b[0;31m       gen_nn_ops.conv2d_backprop_input(\n\u001b[0m\u001b[1;32m    583\u001b[0m           \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1617\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1620\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Conv2DBackpropInput\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m         \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "ale = ALEInterface()\n",
    "\n",
    "\n",
    "\n",
    "config = Config()\n",
    "best_reward = 0\n",
    "\n",
    "#env = gym.make(\"Assault-v4\", render_mode=\"rgb_array\")\n",
    "env = gym.make(\"Assault-v4\") \n",
    "n_actions = env.action_space.n\n",
    "\n",
    "actor_model = Actor(n_actions)\n",
    "print(\"Number of actions:\", n_actions)\n",
    "actor_model.build(input_shape=(None, 210, 160, 3))  # Build the model with the input shape\n",
    "actor_model.summary()\n",
    "dummy_input = np.random.random((1, 210, 160, 3))\n",
    "actor_model(dummy_input)\n",
    "\n",
    "critic_model = Critic()\n",
    "critic_model.build(input_shape=(None, 210, 160, 3))  # Build the model with the input shape\n",
    "critic_model.summary()\n",
    "\n",
    "# Run a dummy input through the model to finalize its construction\n",
    "dummy_input = np.random.random((1, 210, 160, 3))\n",
    "critic_model(dummy_input)\n",
    "\n",
    "\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-4,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "actor_optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "critic_optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "memory = ReplayMemory(config.MEMORY_SIZE)\n",
    "\n",
    "episode_rewards = []\n",
    "epsilon = config.EPSILON_START\n",
    "\n",
    "for episode in range(config.EPISODES):\n",
    "    #state, info = env.reset()\n",
    "    #state = state / 255.0\n",
    "    state = env.reset() / 255.0\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    steps = 0\n",
    "    info ={'ale.lives': 4, 'episode_frame_number': 2, 'frame_number': 2}\n",
    "    frames = []\n",
    "    max_steps = 100\n",
    "\n",
    "    while not done and info.get(\"ale.lives\") > 0: #steps < config.MAX_STEPS_PER_EPISODE and info.get(\"lives\") >= 0:\n",
    "        #action = take_action(state, epsilon)\n",
    "\n",
    "        #step_result = env.step(action)\n",
    "        #next_state, reward, done, _, info = step_result[:5]\n",
    "        #next_state = next_state / 255.0\n",
    "\n",
    "        action = take_action(state, epsilon, env, actor_model, n_actions)\n",
    "        \n",
    "        step_result = env.step(action)\n",
    "        \n",
    "        next_state, reward, done, info = step_result\n",
    "\n",
    "        next_state = next_state / 255.0\n",
    "\n",
    "        memory.push(state, action, next_state, reward, done)\n",
    "        optimize_model(memory, config, critic_model , critic_optimizer, actor_model, actor_optimizer, n_actions)\n",
    "\n",
    "        frame = env.render(mode='rgb_array')\n",
    "        frames.append(frame)\n",
    "\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "\n",
    "        if reward != 0:\n",
    "            print(\"step: \", steps, \"action: \", action, \" reward: \", reward)\n",
    "            print(\"Lives: \", info.get(\"ale.lives\"))\n",
    "\n",
    "        steps += 1\n",
    "\n",
    "    print(f\"Episode: {episode+1}, Reward: {episode_reward}, Epsilon: {epsilon}\")\n",
    "\n",
    "    if episode_reward > best_reward:\n",
    "        best_reward = episode_reward\n",
    "\n",
    "        #CAMBIAR PATH a la carpeta AC\n",
    "        actor_model.save(\"./best_actor_model\", save_format=\"tf\")\n",
    "        \n",
    "        #CAMBIAR PATH a la carpeta AC\n",
    "        critic_model.save(\"./best_critic_model\", save_format=\"tf\")\n",
    "        print(\"New best model saved with reward:\", episode_reward)\n",
    "\n",
    "        gif_path = f\"./episode_{episode+1}_reward_{episode_reward}.gif\"\n",
    "        \n",
    "        imageio.mimsave(gif_path, frames, fps=30)\n",
    "\n",
    "    episode_rewards.append(episode_reward)\n",
    "\n",
    "    epsilon = max((epsilon * config.EPSILON_DECAY_RATE), config.EPSILON_END)\n",
    "\n",
    "    # Log episode metrics and GIF to wandb\n",
    "    wandb.log({\"episode\": episode + 1, \"reward\": episode_reward, \"epsilon\": epsilon, \"episode_gif\": wandb.Video(gif_path, fps=4, format=\"gif\")})\n",
    "\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_rewards(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "action:  1  reward:  21.0\n",
      "Lives:  4\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "action:  3  reward:  21.0\n",
      "Lives:  4\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "action:  1  reward:  21.0\n",
      "Lives:  4\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "action:  5  reward:  21.0\n",
      "Lives:  4\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "action:  3  reward:  21.0\n",
      "Lives:  4\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a6ad9d5b8bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m  \u001b[0;31m# Normaliza los valores de píxeles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a6ad9d5b8bff>\u001b[0m in \u001b[0;36mtake_action\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0maction_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2376\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m             \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2378\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2379\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m             \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 713\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    750\u001b[0m             self._flat_output_types)\n\u001b[1;32m    751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3406\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3408\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3409\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3410\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TEST THE SAVED MODEL\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#CAMBIAR PATH a la carpeta AC\n",
    "actor_model = keras.models.load_model(\"./best_actor_model\")\n",
    "\n",
    "#CAMBIAR PATH a la carpeta AC\n",
    "critic_model = keras.models.load_model(\"./best_critic_model\")\n",
    "\n",
    "env = gym.make(\"Assault-v4\")\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "rewards_per_episode = []\n",
    "best_reward = 0\n",
    "\n",
    "for episode in range(500):\n",
    "    state= env.reset()\n",
    "    state = state / 255.0 \n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    frames = []\n",
    "    info ={'ale.lives': 4, 'episode_frame_number': 2, 'frame_number': 2}\n",
    "\n",
    "    while not done:\n",
    "        action = take_action_test(state, actor_model, n_actions)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = next_state / 255.0  # Normaliza los valores de píxeles\n",
    "\n",
    "        frame = env.render(mode = \"rgb_array\")\n",
    "        frames.append(frame)\n",
    "\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "\n",
    "        if reward != 0:\n",
    "            print(\"action: \", action, \" reward: \", reward)\n",
    "            print(\"Lives: \", info.get(\"ale.lives\"))\n",
    "\n",
    "    rewards_per_episode.append(episode_reward)\n",
    "    print(f\"Episode {episode + 1}: Reward = {episode_reward}\")\n",
    "\n",
    "    if episode_reward > best_reward:\n",
    "        best_reward = episode_reward  \n",
    "        \n",
    "        gif_path = f\"./test_episode_{episode+1}_reward_{episode_reward}.gif\"\n",
    "        imageio.mimsave(gif_path, frames, fps=30)  \n",
    "\n",
    "    # Log episode metrics and GIF to wandb\n",
    "    wandb.log({\"episode\": episode + 1, \"reward\": episode_reward, \"epsilon\": epsilon, \"episode_gif\": wandb.Video(gif_path, fps=4, format=\"gif\")})\n",
    "\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Grafica las recompensas por episodio\n",
    "plt.plot(rewards_per_episode)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Reward per Episode')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
