{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections\n",
    "import gym\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"Assault-v4\")\n",
    "\n",
    "# Set seed for experiment reproducibility\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Small epsilon value for stabilizing division operations\n",
    "eps = np.finfo(np.float32).eps.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ActorCritic(tf.keras.Model):\n",
    "    def __init__(self, num_actions: int, num_hidden_units: int, input_shape: int):\n",
    "        super().__init__()\n",
    "        self.common = layers.Dense(num_hidden_units, activation=\"relu\", input_shape=(input_shape,))\n",
    "        self.actor = layers.Dense(num_actions)\n",
    "        self.critic = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        x = self.common(inputs)\n",
    "        return self.actor(x), self.critic(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = env.action_space.n  \n",
    "input_shape = env.observation_space.shape[0]\n",
    "num_hidden_units = 128\n",
    "\n",
    "\n",
    "\n",
    "model = ActorCritic(num_actions, num_hidden_units, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the environment step function to handle the Assault environment\n",
    "def env_step(action: tf.Tensor) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    state, reward, done, truncated, info = env.step(action.numpy())\n",
    "    return (state.astype(np.float32),\n",
    "            np.array(reward, np.int32),\n",
    "            np.array(done, np.int32))\n",
    "\n",
    "# Wrap the function using tf.numpy_function\n",
    "@tf.function\n",
    "def tf_env_step(action):\n",
    "    return tf.numpy_function(env_step, [action], (tf.float32, tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_episode(\n",
    "    initial_state: tf.Tensor,\n",
    "    model: tf.keras.Model,\n",
    "    max_steps: int) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "    action_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    rewards = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "\n",
    "    initial_state_shape = initial_state.shape\n",
    "    state = initial_state\n",
    "\n",
    "    for t in tf.range(max_steps):\n",
    "        state = tf.expand_dims(state, 0)\n",
    "        action_logits_t, value = model(state)\n",
    "\n",
    "        action_logits_t = tf.squeeze(action_logits_t)\n",
    "        action_logits_t = tf.reshape(action_logits_t, (1, -1))\n",
    "\n",
    "        action = tf.random.categorical(action_logits_t, 1)[0, 0]\n",
    "        action_probs_t = tf.nn.softmax(action_logits_t)\n",
    "\n",
    "        values = values.write(t, tf.squeeze(value))\n",
    "        action_probs = action_probs.write(t, action_probs_t[0, action])\n",
    "\n",
    "        state, reward, done = tf_env_step(action)\n",
    "        state.set_shape(initial_state_shape)\n",
    "\n",
    "        rewards = rewards.write(t, reward)\n",
    "\n",
    "        if tf.cast(done, tf.bool):\n",
    "            break\n",
    "\n",
    "    action_probs = action_probs.stack()\n",
    "    values = values.stack()\n",
    "    rewards = rewards.stack()\n",
    "\n",
    "    return action_probs, values, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_expected_return(\n",
    "    rewards: tf.Tensor,\n",
    "    gamma: float,\n",
    "    standardize: bool = True) -> tf.Tensor:\n",
    "  \"\"\"Compute expected returns per timestep.\"\"\"\n",
    "\n",
    "  n = tf.shape(rewards)[0]\n",
    "  returns = tf.TensorArray(dtype=tf.float32, size=n)\n",
    "\n",
    "  # Start from the end of `rewards` and accumulate reward sums\n",
    "  # into the `returns` array\n",
    "  rewards = tf.cast(rewards[::-1], dtype=tf.float32)\n",
    "  discounted_sum = tf.constant(0.0)\n",
    "  discounted_sum_shape = discounted_sum.shape\n",
    "  for i in tf.range(n):\n",
    "    reward = rewards[i]\n",
    "    discounted_sum = reward + gamma * discounted_sum\n",
    "    discounted_sum.set_shape(discounted_sum_shape)\n",
    "    returns = returns.write(i, discounted_sum)\n",
    "  returns = returns.stack()[::-1]\n",
    "\n",
    "  if standardize:\n",
    "    returns = ((returns - tf.math.reduce_mean(returns)) /\n",
    "               (tf.math.reduce_std(returns) + eps))\n",
    "\n",
    "  return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "def compute_loss(\n",
    "    action_probs: tf.Tensor,\n",
    "    values: tf.Tensor,\n",
    "    returns: tf.Tensor) -> tf.Tensor:\n",
    "  \"\"\"Computes the combined Actor-Critic loss.\"\"\"\n",
    "\n",
    "  advantage = returns - values\n",
    "\n",
    "  action_log_probs = tf.math.log(action_probs)\n",
    "  actor_loss = -tf.math.reduce_sum(action_log_probs * advantage)\n",
    "\n",
    "  critic_loss = huber_loss(values, returns)\n",
    "\n",
    "  return actor_loss + critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "# Update the @tf.function decorator for the train_step function\n",
    "def train_step(\n",
    "    initial_state: tf.Tensor,\n",
    "    model: tf.keras.Model,\n",
    "    optimizer: tf.keras.optimizers.Optimizer,\n",
    "    gamma: float,\n",
    "    max_steps_per_episode: int) -> tf.Tensor:\n",
    "    with tf.GradientTape() as tape:\n",
    "        action_probs, values, rewards = run_episode(\n",
    "            initial_state, model, max_steps_per_episode)\n",
    "        returns = get_expected_return(rewards, gamma)\n",
    "        action_probs, values, returns = [\n",
    "            tf.expand_dims(x, 1) for x in [action_probs, values, returns]]\n",
    "        loss = compute_loss(action_probs, values, returns)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    episode_reward = tf.math.reduce_sum(rewards)\n",
    "    return episode_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node 'PyFunc' defined at (most recent call last):\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n      app.start()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2894, in run_cell\n      result = self._run_cell(\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-33-03758167c590>\", line 23, in <module>\n      result = train_step(initial_state, model, optimizer, gamma, max_steps_per_episode)\n    File \"<ipython-input-32-1ff0cba7ddeb>\", line 13, in train_step\n      action_probs, values, rewards = run_episode(\n    File \"<ipython-input-31-29797df679c2>\", line 12, in run_episode\n      for t in tf.range(max_steps):\n    File \"<ipython-input-31-29797df679c2>\", line 25, in run_episode\n      state, reward, done = tf_env_step(action)\n    File \"<ipython-input-30-bdbe509da182>\", line 11, in tf_env_step\n      return tf.numpy_function(env_step, [action], (tf.float32, tf.int32, tf.int32))\nNode: 'PyFunc'\nAttributeError: 'numpy.int64' object has no attribute 'numpy'\nTraceback (most recent call last):\n\n  File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-30-bdbe509da182>\", line 3, in env_step\n    state, reward, done, truncated, info = env.step(action.numpy())\n\nAttributeError: 'numpy.int64' object has no attribute 'numpy'\n\n\n\t [[{{node PyFunc}}]] [Op:__inference_tf_env_step_770]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-03758167c590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps_per_episode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mepisode_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-1604e444830b>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(initial_state, model, optimizer, gamma, max_steps_per_episode)\u001b[0m\n\u001b[1;32m     10\u001b[0m     max_steps_per_episode: int) -> tf.Tensor:\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         action_probs, values, rewards = run_episode(\n\u001b[0m\u001b[1;32m     13\u001b[0m             initial_state, model, max_steps_per_episode)\n\u001b[1;32m     14\u001b[0m         \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_expected_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-29797df679c2>\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(initial_state, model, max_steps)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_probs_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_env_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node 'PyFunc' defined at (most recent call last):\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n      app.start()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2894, in run_cell\n      result = self._run_cell(\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-33-03758167c590>\", line 23, in <module>\n      result = train_step(initial_state, model, optimizer, gamma, max_steps_per_episode)\n    File \"<ipython-input-32-1ff0cba7ddeb>\", line 13, in train_step\n      action_probs, values, rewards = run_episode(\n    File \"<ipython-input-31-29797df679c2>\", line 12, in run_episode\n      for t in tf.range(max_steps):\n    File \"<ipython-input-31-29797df679c2>\", line 25, in run_episode\n      state, reward, done = tf_env_step(action)\n    File \"<ipython-input-30-bdbe509da182>\", line 11, in tf_env_step\n      return tf.numpy_function(env_step, [action], (tf.float32, tf.int32, tf.int32))\nNode: 'PyFunc'\nAttributeError: 'numpy.int64' object has no attribute 'numpy'\nTraceback (most recent call last):\n\n  File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/Users/roy/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-30-bdbe509da182>\", line 3, in env_step\n    state, reward, done, truncated, info = env.step(action.numpy())\n\nAttributeError: 'numpy.int64' object has no attribute 'numpy'\n\n\n\t [[{{node PyFunc}}]] [Op:__inference_tf_env_step_770]"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "min_episodes_criterion = 100\n",
    "max_episodes = 30000\n",
    "max_steps_per_episode = 1000\n",
    "\n",
    "# `CartPole-v1` is considered solved if average reward is >= 475 over 500\n",
    "# consecutive trials\n",
    "reward_threshold = 10000\n",
    "running_reward = 0\n",
    "\n",
    "# The discount factor for future rewards\n",
    "gamma = 0.99\n",
    "\n",
    "# Keep the last episodes reward\n",
    "episodes_reward: collections.deque = collections.deque(maxlen=min_episodes_criterion)\n",
    "\n",
    "# Usage of the modified code\n",
    "t = tqdm.trange(max_episodes)\n",
    "for i in t:\n",
    "    initial_state = env.reset()\n",
    "    initial_state = tf.constant(initial_state, dtype=tf.float32)\n",
    "    result = train_step(initial_state, model, optimizer, gamma, max_steps_per_episode)\n",
    "    episode_reward = int(result)\n",
    "\n",
    "    episodes_reward.append(episode_reward)\n",
    "    running_reward = statistics.mean(episodes_reward)\n",
    "\n",
    "    t.set_postfix(\n",
    "        episode_reward=episode_reward, running_reward=running_reward)\n",
    "\n",
    "    if running_reward > reward_threshold and i >= min_episodes_criterion:\n",
    "        break\n",
    "\n",
    "print(f'\\nSolved at episode {i}: average reward: {running_reward:.2f}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
