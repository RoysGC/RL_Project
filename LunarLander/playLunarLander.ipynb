{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb\n",
    "wandb.init(project=\"lunarLander_gif_git\", entity=\"rl_proj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import cv2\n",
    "\n",
    "DEVICE=\"cpu\"\n",
    "ACTION_SPACE = [0,1,2,3]\n",
    "EPISODES = 100\n",
    "STEPS = 250\n",
    "RENDER=True\n",
    "\n",
    "class ReinforceNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(ReinforceNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_inputs, 16)\n",
    "        self.fc2 = nn.Linear(16, 32)\n",
    "        self.fc3 = nn.Linear(32, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0) if x.dim() == 1 else x\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        actions = torch.softmax(self.fc3(x), dim=-1)\n",
    "        action = self.get_action(actions)\n",
    "        log_prob_action = torch.log(actions.squeeze(0))[action]\n",
    "        return action, log_prob_action\n",
    "\n",
    "    def get_action(self, actions):\n",
    "        return np.random.choice(ACTION_SPACE, p=actions.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (10,500)\n",
    "fontScale              = 1\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2\n",
    "\n",
    "\n",
    "model = ReinforceNetwork(8, 4).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"/workspaces/RL_Project/outputs/best_parameters_24_11.pth\"))\n",
    "model.eval()\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "print(env.action_space,env.observation_space)\n",
    "fig = plt.figure()\n",
    "ims = []\n",
    "total_rewards_all_episodes = []  # Almacenará las recompensas totales de cada episodio\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    state, _ = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=DEVICE)\n",
    "    episode_rewards = []\n",
    "    for step in range(STEPS):\n",
    "        img = env.render()\n",
    "        action, log_prob = model(state)\n",
    "        state, reward, done, info = env.step(action)[:4]\n",
    "        state = torch.tensor(state, dtype=torch.float32, device=DEVICE)\n",
    "        episode_rewards.append(reward)\n",
    "\n",
    "        # Visualización y almacenamiento de la imagen\n",
    "        cv2_im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        pil_im = Image.fromarray(cv2_im_rgb)\n",
    "        draw = ImageDraw.Draw(pil_im)\n",
    "        draw.text((0, 0), f\"Step: {step} Action: {action} Reward: {int(reward)} Total Rewards: {int(np.sum(episode_rewards))} done: {done}\", fill=\"#FDFEFE\")\n",
    "        img = cv2.cvtColor(np.array(pil_im), cv2.COLOR_RGB2BGR)\n",
    "        im = plt.imshow(img, animated=True)\n",
    "        ims.append([im])\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    total_rewards_all_episodes.append(np.sum(episode_rewards))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Graficar la suma de recompensas por episodio\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(total_rewards_all_episodes)\n",
    "plt.title(\"Reward return for episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward return\")\n",
    "plt.grid()\n",
    "\n",
    "wandb.log({\"Reward return for episode\": wandb.Image(plt)})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Guardar la animación\n",
    "Writer = animation.writers['pillow']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "im_ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=3000, blit=True)\n",
    "im_ani.save('gif_git.gif', writer=writer)\n",
    "\n",
    "\n",
    "\n",
    "# Log the GIF to wandb\n",
    "wandb.log({\"animation\": wandb.Video(\"gif_git.gif\", fps=4, format=\"gif\")})\n",
    "\n",
    "# Finish the wandb run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
