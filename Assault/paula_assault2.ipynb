{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 11:22:25.014419: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 11:22:25.130195: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-28 11:22:25.130243: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-28 11:22:25.164542: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-28 11:22:25.194021: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 11:22:25.194909: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-28 11:22:28.245249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment Assault-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.warn(\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "\n",
      "Episodio: 1, Recompensa: 0.0, Epsilon: 0.995050000000002\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "\n",
      "Episodio: 2, Recompensa: 0.0, Epsilon: 0.990100000000004\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "action:  2  reward:  21.0\n",
      "action:  0  reward:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 11:22:35.250281: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 103219200 exceeds 10% of free system memory.\n",
      "2023-11-28 11:22:35.311445: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51609600 exceeds 10% of free system memory.\n",
      "2023-11-28 11:22:35.354738: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65814528 exceeds 10% of free system memory.\n",
      "2023-11-28 11:22:35.466682: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65814528 exceeds 10% of free system memory.\n",
      "2023-11-28 11:22:35.512369: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65814528 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "\n",
      "Episodio: 3, Recompensa: 21.0, Epsilon: 0.985150000000006\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  21.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  21.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "\n",
      "Episodio: 4, Recompensa: 42.0, Epsilon: 0.980200000000008\n",
      "action:  4  reward:  0.0\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  21.0\n",
      "action:  2  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "\n",
      "Episodio: 5, Recompensa: 21.0, Epsilon: 0.9752500000000099\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "\n",
      "Episodio: 6, Recompensa: 0.0, Epsilon: 0.9703000000000119\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "1/1 [==============================] - 1s 775ms/step\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  21.0\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "\n",
      "Episodio: 7, Recompensa: 21.0, Epsilon: 0.9653500000000139\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "\n",
      "Episodio: 8, Recompensa: 0.0, Epsilon: 0.9604000000000159\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "\n",
      "Episodio: 9, Recompensa: 0.0, Epsilon: 0.9554500000000179\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  21.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "\n",
      "Episodio: 10, Recompensa: 21.0, Epsilon: 0.9505000000000199\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "\n",
      "Episodio: 11, Recompensa: 0.0, Epsilon: 0.9455500000000219\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  21.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  21.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "\n",
      "Episodio: 12, Recompensa: 42.0, Epsilon: 0.9406000000000239\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  21.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "\n",
      "Episodio: 13, Recompensa: 21.0, Epsilon: 0.9356500000000258\n",
      "action:  2  reward:  0.0\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  21.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "\n",
      "Episodio: 14, Recompensa: 21.0, Epsilon: 0.9307000000000278\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "\n",
      "Episodio: 15, Recompensa: 0.0, Epsilon: 0.9257500000000298\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "action:  4  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "\n",
      "Episodio: 16, Recompensa: 0.0, Epsilon: 0.9208000000000318\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  21.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "\n",
      "Episodio: 17, Recompensa: 21.0, Epsilon: 0.9158500000000338\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "\n",
      "Episodio: 18, Recompensa: 0.0, Epsilon: 0.9109000000000358\n",
      "action:  0  reward:  0.0\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "action:  3  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "action:  6  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  4  reward:  0.0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  6  reward:  0.0\n",
      "action:  1  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  3  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  0  reward:  0.0\n",
      "action:  5  reward:  0.0\n",
      "action:  2  reward:  0.0\n",
      "action:  5  reward:  0.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from collections import namedtuple, deque\n",
    "import time\n",
    "from ale_py import ALEInterface\n",
    "import imageio\n",
    "\n",
    "ale = ALEInterface()\n",
    "\n",
    "# Inicialización del entorno\n",
    "env = gym.make(\"Assault-v0\", render_mode=\"rgb_array\")\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Parámetros modificados para una mayor exploración inicial y un decaimiento más lento\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.01\n",
    "EPSILON_DECAY = 10000  # Aumenta para un decaimiento más lento\n",
    "EPISODES = 100  # Más episodios para permitir un aprendizaje más prolongado\n",
    "TARGET_UPDATE = 5\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "MAX_STEPS_PER_EPISODE = 200\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "        self.transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(self.transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class DQN(keras.Model):\n",
    "\n",
    "    def __init__(self, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.layer1 = layers.Conv2D(16, 5, strides=2, activation=\"relu\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.layer2 = layers.Conv2D(16, 5, strides=2, activation=\"relu\")\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.layer3 = layers.Conv2D(32, 5, strides=2, activation=\"relu\")\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.layer4 = layers.Dense(512, activation=\"relu\")\n",
    "        self.action = layers.Dense(n_actions, activation=\"linear\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.layer1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer4(x)\n",
    "        return self.action(x)\n",
    "\n",
    "# Creación del modelo y la memoria\n",
    "model = DQN(n_actions)\n",
    "model_target = DQN(n_actions)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "# Preparación del optimizador y la función de pérdida\n",
    "optimizer = keras.optimizers.Adam(learning_rate=2.5e-4, clipnorm=1.0)\n",
    "loss_function = keras.losses.Huber()\n",
    "\n",
    "def take_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        q_values = model.predict(state[np.newaxis, ...])\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "def optimize_model():\n",
    "    if memory.__len__() < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = memory.transition(*zip(*transitions))\n",
    "\n",
    "    state_batch = np.array(batch.state)\n",
    "    action_batch = np.array(batch.action)\n",
    "    next_state_batch = np.array(batch.next_state)\n",
    "    rewad_batch = np.array(batch.reward)\n",
    "    done_batch = np.array(batch.done, dtype=np.int8)\n",
    "\n",
    "    future_rewards = model_target(next_state_batch)\n",
    "    target = rewad_batch + GAMMA * tf.reduce_max(future_rewards, axis=-1) * (1 - done_batch)\n",
    "\n",
    "    action_mask = tf.one_hot(action_batch, n_actions)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        q_values = model(state_batch)\n",
    "        q_action = tf.reduce_sum(tf.multiply(q_values, action_mask), axis=-1)\n",
    "        loss = loss_function(target, q_action)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    #model.save_weights('/Users/roy/Desktop/UNI')\n",
    "\n",
    "# Entrenamiento del agente\n",
    "epsilon = EPSILON_START\n",
    "for episode in range(EPISODES):\n",
    "    state, info = env.reset()  \n",
    "    state = state / 255.0\n",
    "    #state = env.reset() / 255.0\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    steps = 0\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    while not done and steps < MAX_STEPS_PER_EPISODE:\n",
    "        frame = env.render()\n",
    "        frames.append(frame)\n",
    "\n",
    "        action = take_action(state, epsilon)\n",
    "        step_result = env.step(action)\n",
    "        next_state, reward, done, _ = step_result[:4]\n",
    "        next_state = next_state / 255.0\n",
    "\n",
    "        memory.push(state, action, next_state, reward, done)\n",
    "        optimize_model()\n",
    "\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "        epsilon = max(epsilon - (EPSILON_START - EPSILON_END) / EPSILON_DECAY, EPSILON_END)\n",
    "        \n",
    "        print(\"action: \", action, \" reward: \", reward)\n",
    "    print(f\"\\nEpisodio: {episode+1}, Recompensa: {episode_reward}, Epsilon: {epsilon}\")\n",
    "\n",
    "    #gif_path = f\"episode_{episode+1}.gif\"\n",
    "    gif_path = f\"/workspaces/RL_Project/Assault_gifs/episode_{episode+1}.gif\"\n",
    "    imageio.mimsave(gif_path, frames, format='GIF', fps=30)\n",
    "\n",
    "    if (episode + 1) % TARGET_UPDATE == 0:\n",
    "        model_target.set_weights(model.get_weights())\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
