{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.16.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from wandb) (5.9.6)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /home/codespace/.local/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from wandb) (68.2.2)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Installing collected packages: appdirs, setproctitle, sentry-sdk, protobuf, docker-pycreds, Click, wandb\n",
      "Successfully installed Click-8.1.7 appdirs-1.4.4 docker-pycreds-0.4.0 protobuf-4.25.1 sentry-sdk-1.38.0 setproctitle-1.3.3 wandb-0.16.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /home/codespace/.local/lib/python3.10/site-packages (from gym) (1.26.2)\n",
      "Collecting cloudpickle>=1.2.0 (from gym)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting gym-notices>=0.0.4 (from gym)\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827619 sha256=3e9b0a35a151802bc1997a9edde18feee5aeda4e44e824a19670a0b5666b1e6c\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, cloudpickle, gym\n",
      "Successfully installed cloudpickle-3.0.0 gym-0.26.2 gym-notices-0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0 (from tensorflow)\n",
      "  Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.26.2)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (4.25.1)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (4.8.0)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading google_auth-2.25.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.2/184.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, ml-dtypes, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, astunparse, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.1\n",
      "    Uninstalling protobuf-4.25.1:\n",
      "      Successfully uninstalled protobuf-4.25.1\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.25.2 google-auth-oauthlib-1.1.0 google-pasta-0.2.0 grpcio-1.60.0 h5py-3.10.0 keras-2.15.0 libclang-16.0.6 markdown-3.5.1 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.4.0 werkzeug-3.0.1 wheel-0.42.0 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Downloading imageio-2.33.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from imageio) (1.26.2)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/codespace/.local/lib/python3.10/site-packages (from imageio) (10.1.0)\n",
      "Downloading imageio-2.33.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imageio\n",
      "Successfully installed imageio-2.33.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ale-py\n",
      "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from ale-py) (1.26.2)\n",
      "Collecting importlib-resources (from ale-py)\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/codespace/.local/lib/python3.10/site-packages (from ale-py) (4.8.0)\n",
      "Downloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: importlib-resources, ale-py\n",
      "Successfully installed ale-py-0.8.1 importlib-resources-6.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ale-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[accept-rom-license] in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/codespace/.local/lib/python3.10/site-packages (from gym[accept-rom-license]) (1.26.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from gym[accept-rom-license]) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from gym[accept-rom-license]) (0.0.8)\n",
      "Collecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license])\n",
      "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: click in /usr/local/python/3.10.13/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (8.1.7)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2.31.0)\n",
      "Collecting tqdm (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license])\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license])\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2023.7.22)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: AutoROM.accept-rom-license\n",
      "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=d6c499225a46f566e4559bee8650684b8ef2e978fcfea51e65342d9970a9bdfd\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
      "Successfully built AutoROM.accept-rom-license\n",
      "Installing collected packages: tqdm, AutoROM.accept-rom-license, autorom\n",
      "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2 tqdm-4.66.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym[accept-rom-license]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 18:42:31.554581: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 18:42:31.592558: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 18:42:31.592598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 18:42:31.593874: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 18:42:31.600017: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 18:42:31.600971: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 18:42:32.584934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = all messages, 1 = filter out INFO, 2 = filter out WARNING, 3 = filter out ERROR\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import logging\n",
    "gym_logger = logging.getLogger('gym')\n",
    "gym_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API KEY: 73c9a156b91f3e0c01c3d5f332d23bfc66f4cdbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1630423\u001b[0m (\u001b[33mrl_proj\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Project/Assault/wandb/run-20231211_184235-i74m4gfx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rl_proj/AC_prova/runs/i74m4gfx' target=\"_blank\">chocolate-waterfall-6</a></strong> to <a href='https://wandb.ai/rl_proj/AC_prova' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rl_proj/AC_prova' target=\"_blank\">https://wandb.ai/rl_proj/AC_prova</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rl_proj/AC_prova/runs/i74m4gfx' target=\"_blank\">https://wandb.ai/rl_proj/AC_prova/runs/i74m4gfx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rl_proj/AC_prova/runs/i74m4gfx?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f6f58283fd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"ActorCritic\", entity = \"rl_proj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from collections import namedtuple, deque\n",
    "from ale_py import ALEInterface\n",
    "import wandb\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "ale = ALEInterface()\n",
    "\n",
    "class Config:\n",
    "    EPSILON_START = 1.0\n",
    "    EPSILON_END = 0.01\n",
    "    EPSILON_DECAY_RATE = 0.99\n",
    "    EPISODES = 1500  \n",
    "    BATCH_SIZE = 128\n",
    "    GAMMA = 0.999\n",
    "    MAX_STEPS_PER_EPISODE = 1000\n",
    "    LEARNING_RATE = 1e-4 \n",
    "    MEMORY_SIZE = 10000\n",
    "\n",
    "config = Config()\n",
    "best_reward = 0\n",
    "\n",
    "env = gym.make(\"Assault-v4\", render_mode=\"rgb_array\")\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "        self.transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(self.transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "\n",
    "class Actor(keras.Model):\n",
    "    def __init__(self, n_actions):\n",
    "        super(Actor, self).__init__()\n",
    "        #self.conv1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")\n",
    "        self.conv1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\", kernel_initializer='he_normal')\n",
    "        #self.conv2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")\n",
    "        self.conv2 = layers.Conv2D(64, 4, strides=2, activation=None)  # Remove activation here\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.conv3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.d1 = layers.Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))\n",
    "        self.d2 = layers.Dense(n_actions, activation=\"softmax\")  # Output layer for action probabilities\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        #x = self.conv2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.nn.relu(self.batch_norm1(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "\n",
    "class Critic(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")\n",
    "        self.conv2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")\n",
    "        self.conv3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.d1 = layers.Dense(512, activation=\"relu\")\n",
    "        self.d2 = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "\n",
    "actor_model = Actor(n_actions)\n",
    "print(\"Number of actions:\", n_actions)\n",
    "actor_model.build(input_shape=(None, 210, 160, 3))  # Build the model with the input shape\n",
    "actor_model.summary()\n",
    "critic_model = Critic()\n",
    "\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-4,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "actor_optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "critic_optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "memory = ReplayMemory(config.MEMORY_SIZE)\n",
    "\n",
    "\n",
    "def take_action(state, epsilon):\n",
    "\n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        action_probabilities = actor_model.predict(state[np.newaxis, ...])\n",
    "        print(\"Action probabilities:\", action_probabilities)\n",
    "\n",
    "        if np.isnan(action_probabilities).any():\n",
    "            print(\"NaN detected in action probabilities\")\n",
    "            return env.action_space.sample() \n",
    "        return np.random.choice(n_actions, p=np.squeeze(action_probabilities))\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < config.BATCH_SIZE:\n",
    "        return  # Exit the function if not enough samples\n",
    "\n",
    "    # Sample a batch of transitions from the replay memory\n",
    "    transitions = memory.sample(config.BATCH_SIZE)\n",
    "    batch = memory.transition(*zip(*transitions))\n",
    "\n",
    "    # Convert the batches into numpy arrays for processing\n",
    "    state_batch = np.array(batch.state)\n",
    "    action_batch = np.array(batch.action)\n",
    "    reward_batch = np.array(batch.reward)\n",
    "    next_state_batch = np.array(batch.next_state)\n",
    "    done_batch = np.array(batch.done)\n",
    "\n",
    "    # Critic Update\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get the values from the Critic model\n",
    "        values = critic_model(state_batch)\n",
    "        # Create a dummy target for simplicity\n",
    "        dummy_target = tf.random.uniform(shape=values.shape)\n",
    "        # Compute a simple mean squared error\n",
    "\n",
    "        values_squeezed = tf.squeeze(values)\n",
    "        if len(values_squeezed.shape) > 1:\n",
    "            raise ValueError(\"Critic model's output is not a 1D array\")\n",
    "\n",
    "        critic_loss = tf.math.reduce_mean(tf.math.square(dummy_target - values))\n",
    "\n",
    "    critic_grads = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "    critic_grads, _ = tf.clip_by_global_norm(critic_grads, 1.0)  # Gradient clipping\n",
    "    critic_optimizer.apply_gradients(zip(critic_grads, critic_model.trainable_variables))\n",
    "\n",
    "    # Debugging: Print gradients and corresponding variables\n",
    "    for grad, var in zip(critic_grads, critic_model.trainable_variables):\n",
    "        if grad is None:\n",
    "            print(f\"Gradient is None for variable {var.name}\")\n",
    "\n",
    "    # Filter out None gradients\n",
    "    critic_grads_and_vars = [(grad, var) for grad, var in zip(critic_grads, critic_model.trainable_variables) if grad is not None]\n",
    "\n",
    "    # Apply gradients if there are valid ones\n",
    "    if critic_grads_and_vars:\n",
    "        critic_optimizer.apply_gradients(critic_grads_and_vars)\n",
    "    else:\n",
    "        print(\"No valid gradients to apply.\")\n",
    "\n",
    "    # Actor Update\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Predict the action probabilities for the current state\n",
    "        #print(\"Input shape to the model:\", state_batch.shape)\n",
    "        action_probs = actor_model(state_batch)\n",
    "        # Create a one-hot encoded mask for the taken actions\n",
    "        action_mask = tf.one_hot(action_batch, n_actions)\n",
    "        # Select the probabilities for the actions that were actually taken\n",
    "        selected_action_probs = tf.reduce_sum(action_probs * action_mask, axis=1)\n",
    "\n",
    "        # Adjust dummy target values shape to match the values\n",
    "        dummy_target_values = np.zeros_like(values_squeezed.numpy())\n",
    "        advantage = dummy_target_values - values_squeezed\n",
    "\n",
    "        epsilon = 1e-8\n",
    "        actor_loss = -tf.math.reduce_mean(tf.math.log(selected_action_probs + epsilon) * advantage)\n",
    "        #actor_loss = -tf.math.reduce_mean(tf.math.log(selected_action_probs) * advantage)\n",
    "\n",
    "    actor_grads = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "    actor_grads, _ = tf.clip_by_global_norm(actor_grads, 0.5)  # Gradient clipping\n",
    "    actor_optimizer.apply_gradients(zip(actor_grads, actor_model.trainable_variables))\n",
    "    for grad in actor_grads:\n",
    "        if tf.reduce_any(tf.math.is_inf(grad)).numpy() or tf.reduce_any(tf.math.is_nan(grad)).numpy():\n",
    "            print(\"Inf or NaN detected in actor gradients\")\n",
    "\n",
    "episode_rewards = []\n",
    "epsilon = config.EPSILON_START\n",
    "\n",
    "for episode in range(config.EPISODES):\n",
    "    state, info = env.reset()\n",
    "    state = state / 255.0\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    steps = 0\n",
    "    info ={'lives': 4, 'episode_frame_number': 2, 'frame_number': 2}\n",
    "    frames = []\n",
    "\n",
    "    while not done and info.get(\"lives\") >0: #steps < config.MAX_STEPS_PER_EPISODE and info.get(\"lives\") >= 0:\n",
    "        action = take_action(state, epsilon)\n",
    "\n",
    "        step_result = env.step(action)\n",
    "        next_state, reward, done, _, info = step_result[:5]\n",
    "        next_state = next_state / 255.0\n",
    "\n",
    "        #next_state, reward, done, _, info = env.step(action)\n",
    "        #next_state = next_state / 255.0\n",
    "\n",
    "        memory.push(state, action, next_state, reward, done)\n",
    "        optimize_model()\n",
    "\n",
    "        frame = env.render()\n",
    "        frames.append(frame)\n",
    "\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "\n",
    "        if reward != 0:\n",
    "            print(\"step: \", steps, \"action: \", action, \" reward: \", reward)\n",
    "            print(\"Lives: \", info.get(\"lives\"))\n",
    "\n",
    "        steps += 1\n",
    "\n",
    "    print(f\"Episode: {episode+1}, Reward: {episode_reward}, Epsilon: {epsilon}\")\n",
    "\n",
    "    if episode_reward > best_reward:\n",
    "      best_reward = episode_reward\n",
    "      #CAMBIAR PATH\n",
    "      actor_model.save(f\"/workspaces/RL_Project/Assault/AC/best_actor_model\", save_format=\"tf\")\n",
    "      #CAMBIAR PATH\n",
    "      critic_model.save(f\"/workspaces/RL_Project/Assault/AC/best_critic_model\", save_format=\"tf\")\n",
    "      print(\"New best model saved with reward:\", episode_reward)\n",
    "\n",
    "    episode_rewards.append(episode_reward)\n",
    "\n",
    "    epsilon = max((epsilon * config.EPSILON_DECAY_RATE), config.EPSILON_END)\n",
    "    #CAMBIAR PATH\n",
    "    gif_path = f\"/workspaces/RL_Project/Assault/AC/episode_{episode+1}_reward_{episode_reward}.gif\"\n",
    "    \n",
    "    imageio.mimsave(gif_path, frames, fps=30)\n",
    "\n",
    "    # Log episode metrics and GIF to wandb\n",
    "    wandb.log({\"episode\": episode + 1, \"reward\": episode_reward, \"epsilon\": epsilon, \"episode_gif\": wandb.Video(gif_path, fps=4, format=\"gif\")})\n",
    "\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(episode_rewards)\n",
    "plt.title(\"Rewards per Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.grid(True)\n",
    "#CAMBIAR PATH\n",
    "plot_path = \"/workspaces/RL_Project/Assault/AC/rewards_plot.png\"\n",
    "plt.savefig(plot_path)\n",
    "\n",
    "# Log the plot to WandB\n",
    "wandb.log({\"Training process of Actor-Critic\": wandb.Image(plot_path)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#TEST THE SAVED MODEL\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carga los modelos\n",
    "#CAMBIAR PATH\n",
    "actor_model = keras.models.load_model(f\"/workspaces/RL_Project/Assault/AC/best_actor_model\")\n",
    "#CAMBIAR PATH\n",
    "critic_model = keras.models.load_model(f\"/workspaces/RL_Project/Assault/AC/best_critic_model\")\n",
    "\n",
    "# Crea el entorno\n",
    "env = gym.make(\"Assault-v4\", render_mode=\"rgb_array\")\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "def take_action(state):\n",
    "    action_probabilities = actor_model.predict(state[np.newaxis, ...])\n",
    "    return np.random.choice(n_actions, p=np.squeeze(action_probabilities))\n",
    "\n",
    "# Evalúa el modelo en 10 episodios\n",
    "rewards_per_episode = []\n",
    "for episode in range(500):\n",
    "    state, _ = env.reset()\n",
    "    state = state / 255.0  # Normaliza los valores de píxeles\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    frames = []\n",
    "    info ={'lives': 4, 'episode_frame_number': 2, 'frame_number': 2}\n",
    "\n",
    "    while not done:\n",
    "        action = take_action(state)\n",
    "        next_state, reward, done, _, info = env.step(action)\n",
    "        next_state = next_state / 255.0  # Normaliza los valores de píxeles\n",
    "\n",
    "        frame = env.render()\n",
    "        frames.append(frame)\n",
    "\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "\n",
    "        if reward != 0:\n",
    "            print(\"step: \", steps, \"action: \", action, \" reward: \", reward)\n",
    "            print(\"Lives: \", info.get(\"lives\"))\n",
    "\n",
    "    rewards_per_episode.append(episode_reward)\n",
    "    print(f\"Episode {episode + 1}: Reward = {episode_reward}\")\n",
    "\n",
    "    #CAMBIAR PATH\n",
    "    gif_path = f\"/workspaces/RL_Project/Assault/AC/test_episode_{episode+1}_reward_{episode_reward}.gif\"\n",
    "    imageio.mimsave(gif_path, frames, fps=30)\n",
    "\n",
    "    # Log episode metrics and GIF to wandb\n",
    "    wandb.log({\"episode\": episode + 1, \"reward\": episode_reward, \"epsilon\": epsilon, \"episode_gif\": wandb.Video(gif_path, fps=4, format=\"gif\")})\n",
    "\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Grafica las recompensas por episodio\n",
    "plt.plot(rewards_per_episode)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Reward per Episode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
